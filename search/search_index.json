{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Welcome to personal space I'm a french IT guy working in Luxembourg for an IT company. I'm passionated by Sci-fi, Heroic-Fantasy, Technology, Linux and FreeBSD. As a passionated IT guy I try to push my self behond my limits and other's limits. Trying to improve processes, methods, make IT simple (KISS !!), industrialization and automation are some let-motiv. You will find here some tips and tricks, documentations, memories stored for later usage.","title":"Welcome to personal space"},{"location":"#welcome-to-personal-space","text":"I'm a french IT guy working in Luxembourg for an IT company. I'm passionated by Sci-fi, Heroic-Fantasy, Technology, Linux and FreeBSD. As a passionated IT guy I try to push my self behond my limits and other's limits. Trying to improve processes, methods, make IT simple (KISS !!), industrialization and automation are some let-motiv. You will find here some tips and tricks, documentations, memories stored for later usage.","title":"Welcome to personal space"},{"location":"softs/","text":"Software Toolbox Here is a software list I use or used. Linux Useful tool Tmux zsh and oh-my-zsh TextEditor SublimeText 3 IDE Pycharm Reporting Jaspersoft PasswordSafe A J2E application password manager, multi user. Enterprise Password Safe A password manager based on gpg Pass Bitwarden Business Process Modelor (BPM) Bonita Open Solution","title":"Softs"},{"location":"softs/#software-toolbox","text":"Here is a software list I use or used.","title":"Software Toolbox"},{"location":"softs/#linux-useful-tool","text":"Tmux zsh and oh-my-zsh","title":"Linux Useful tool"},{"location":"softs/#texteditor","text":"SublimeText 3","title":"TextEditor"},{"location":"softs/#ide","text":"Pycharm","title":"IDE"},{"location":"softs/#reporting","text":"Jaspersoft","title":"Reporting"},{"location":"softs/#passwordsafe","text":"A J2E application password manager, multi user. Enterprise Password Safe A password manager based on gpg Pass Bitwarden","title":"PasswordSafe"},{"location":"softs/#business-process-modelor-bpm","text":"Bonita Open Solution","title":"Business Process Modelor (BPM)"},{"location":"IT/","text":"IT Stuff Some documentations, snippets used in my daily job or in my labs FreeIPA","title":"IT Stuff"},{"location":"IT/#it-stuff","text":"Some documentations, snippets used in my daily job or in my labs","title":"IT Stuff"},{"location":"IT/#freeipa","text":"","title":"FreeIPA"},{"location":"IT/bookmarks/","text":"Overall This is some bookmark about tools I've discovered, used or heared about. Reporting JasperSoft Inventory / CMDB GLPI OCS Inventory BPM Bonitasoft Versioning system GIT GOGS Automatic Installation Tools : The Foreman Puppet Katello Ansible RedHat Satellite Databases https://www.yugabyte.com/ Server Tooling Bandwith Usage per process","title":"Bookmarks"},{"location":"IT/bookmarks/#overall","text":"This is some bookmark about tools I've discovered, used or heared about.","title":"Overall"},{"location":"IT/bookmarks/#reporting","text":"JasperSoft","title":"Reporting"},{"location":"IT/bookmarks/#inventory-cmdb","text":"GLPI OCS Inventory","title":"Inventory / CMDB"},{"location":"IT/bookmarks/#bpm","text":"Bonitasoft","title":"BPM"},{"location":"IT/bookmarks/#versioning-system","text":"GIT GOGS","title":"Versioning system"},{"location":"IT/bookmarks/#automatic-installation-tools","text":"The Foreman Puppet Katello Ansible RedHat Satellite","title":"Automatic Installation Tools :"},{"location":"IT/bookmarks/#databases","text":"https://www.yugabyte.com/","title":"Databases"},{"location":"IT/bookmarks/#server-tooling","text":"Bandwith Usage per process","title":"Server Tooling"},{"location":"IT/freeipa/","text":"Introduction About In order to make my infrastructure more easy to manage, I decide to install a FreeIPA server. One of my ex-colleague talked to me a lot about this product times ago. So I decided to try it. NB. This article is not yet finished so some typos can still be included or paragraph not yet formatted. Objectives Install a functional FreeIPA server to : manage users and groups Centralise User SSH keys Automount This is the first step, I will add new modules after FreeOTP Requirements A CentOS machine (10G HD System, 1 VCPU, 2G RAM ) a local domain name like myplace.local References This article is based on : - FreeIPA - UnixMen Core Installation Prepare the machine Add your machine ip and name in your /etc/hosts file echo \"$(ip -o -4 addr show | grep -v \" lo\" | head -1 | awk {'print $4'} | cut -d'/' -f1) $(hostname) $(hostname -s)\" >> /etc/hosts That would add something like : 10.0.0.1 ipaserver.myplace.local ipaserver Install the software Install the requirements to setup everything : yum install ipa-server bind-dyndb-ldap ipa-server-dns Prepare the following infos before executing the install process : domain name (myplace.local) will be determined based on machine hostname, you just have to confirm it Directory Manager password IPA admin password A DNS Forwarder ipa-server-install --setup-dns Answer the questions At the end the following message will appear : Be sure to back up the CA certificates stored in /root/cacert.p12 These files are required to create replicas. The password for these files is the Directory Manager password Backup this file Firewall if you want to use the local firewall on the centos, allow incoming traffic: firewall-cmd --permanent --add-service=ntp firewall-cmd --permanent --add-service=http firewall-cmd --permanent --add-service=https firewall-cmd --permanent --add-service=ldap firewall-cmd --permanent --add-service=ldaps firewall-cmd --permanent --add-service=kerberos firewall-cmd --permanent --add-service=kpasswd If you want to use your FreeIPA to hande also the PKI part, add the RootCA, located in /etc/ipa/ca.crt, in your firefox or system's CA. Configure FreeIPA Everything can be done through a web interface or commands lines. I will use command line. The web interface is reachable through https://ipaserver.myplace.local/ User Management A NFS Server will be used in order to have a unique point of storage for home dir. This will avoid to have multiple time the same data over multiple machine. The NFS Server will be a freebsd server with ZFS Storage. NFS Mount configuration for homedir On FreeIPA Server : ipaserver# ipa automountmap-add default auto.home Added automount map \"auto.home\" Map: auto.home ipaserver# ipa automountkey-add default --key \"/exports/home\" --info auto.home auto.master Added automount key \"/exports/home\" Key: /exports/home Mount information: auto.home ipaserver# ipa automountkey-add default --key \"*\" --info \"-fstype=nfs4,rw,sec=krb5,soft,rsize=8192,wsize=8192 nfssrv.myplace.local:/exports/home/&\" auto.home Added automount key \"*\" Key: * Mount information: -fstype=nfs4,rw,sec=krb5,soft,rsize=8192,wsize=8192 nfssrv.myplace.local:/exports/home/& On Linux machines ensure that home dir will be created automatically if it doesn't exist. authconfig --enablemkhomedir --update Linux Linux NFS Server Source : https://blog.delouw.ch/2015/03/14/using-ipa-to-provide-automount-maps-for-nfsv4-home-directories/ Configure sssd + krb5.conf ipa service-add nfs/nfssrv.myplace.local ipa-getkeytab -s ipasrv.myplace.local -p nfs/nfssrv.myplace.local -k /etc/krb5.keytab Linux IPA Client ipa-server# ipa host-add ipaclient2.myplace.local --ip-address=A.B.C.D ipa-server# ipa service-add nfs/ipaclient2.myplace.local ipa-client# yum install ipa-client ipa-client# mkdir -p /exports/home ipa-client# authconfig --enablemkhomedir --update ipa-client# generate /etc/krb5.conf ipa-client# kinit ipa-client# ipa-getkeytab -s ipasrv.myplace.local -p nfs/${HOSTNAME} -k /etc/krb5.keytab ipa-client# ipa-client-install Or ipa-client# ipa-client-install --domain=myplace.local --server=ipaserver.myplace.local --realm=MYPLACE.LOCAL ipa-client# ipa-client-automount --location=default Ensure that a mount | grep auto return auto.home on /exports/home type autofs (rw,relatime,fd=18,pgrp=19004,timeout=300,minproto=5,maxproto=5,indirect) If not edit /etc/nsswitch.conf find the automount line, sss may be missing it should be like : automount: files sss Fix it, restart sssd and autofs. FreeBSD FreeBSD NFS Server FreeBSD IPA Client Source : - https://blog.hostileadmin.com/2016/03/24/integrating-freebsd-w-freeipasssd/ - https://forums.freebsd.org/threads/46526/ On the FreeBSD Client (not yet functionnal) compile sssd with smb support and --with-krb5-conf=/etc/krb5.conf in sssd/Makefile (thx https://community.riocities.com/freebsd_nfv4_krb.html) mkdir -p /usr/compat/linux/proc echo \"linproc /usr/compat/linux/proc linprocfs rw 0 0\" >> /etc/fstab mkdir /var/log/krb5 edit /etc/pam.d/system on the FreeIPA Server ipa-host-add FREEBSD_FQDN ipa-getkeytab -s ${HOSTNAME} -p host/FREEBSD_FQDN -k copy the newly created keytab file to /etc/krb5.keytab on the FreeBSD Client Add TLS_CACERT /etc/ipa/ca.crt in /usr/local/etc/openldap/ldap.conf Allow some users to connect through ssh Based on http://www.freeipa.org/page/Howto/HBAC_and_allow_all Create a new rule name allow_ssh ipaserver# ipa hbacrule-add allow_ssh Added HBAC rule \"allow_ssh\" Rule name: allow_ssh Enabled: TRUE Associate newly created HBAC rule ipaserver# ipa hbacrule-add-service allow_ssh --hbacsvcs=sshd Rule name: allow_ssh Enabled: TRUE Services: sshd Number of members added 1 Associate a User to this rule ipaserver# ipa hbacrule-add-user allow_ssh --user=username_allowed Rule name: allow_ssh Enabled: TRUE Users: username_allowed Number of members added 1 ipaserver# ipa hbacrule-add-host allow_ssh --hosts=ipaclient.myplace.local Rule name: allow_ssh Enabled: TRUE Users: username_allowed Hosts: ipaclient.myplace.local Number of members added 1 Allow some users to excute commands with sudo In the previous section about allowing ssh command, I've written the command output, but in the following one, I will not. Before allowing user to execute specific command through sudo, we need to allow the user to access sudo. ipaserver# ipa hbacrule-add allow_sudo ipaserver# ipa hbacrule-add-service allow_sudo --hbacsvcs=sudo ipaserver# ipa hbacrule-add-user allow_sudo --user=username_allowed ipaserver# ipa hbacrule-add-host allow_sudo --hosts=ipaclient.myplace.local Ok now let's allow the user execute a command like whoami. Beware that sssd is a caching system so I can take time to refresh the data (up to 6h) - Incrementally, meaning only changes to rules since the last full update (ldap_sudo_smart_refresh_interval, the time in seconds); the default is 15 minutes, - Fully, which dumps the entire caches and pulls in all of the current rules on the LDAP server(ldap_sudo_full_refresh_interval, the time in seconds); the default is six hours. Source sssd-ldap-sudo ipaserver# ipa sudorule-add whoami ipaserver# ipa sudocmd-add /usr/bin/whoami ipaserver# ipa sudorule-add-allow-command whoami --sudocmds /usr/bin/whoami ipaserver# ipa sudorule-add-host whoami --hosts ipaclient.myplace.local ipaserver# ipa sudorule-add-user whoami --users username_allowed Now if we want to allow to execute sudo whoami without autenticate the user we add this: ipaserver# ipa sudorule-add-option whoami --sudooption '!authenticate'","title":"freeipa"},{"location":"IT/freeipa/#introduction","text":"","title":"Introduction"},{"location":"IT/freeipa/#about","text":"In order to make my infrastructure more easy to manage, I decide to install a FreeIPA server. One of my ex-colleague talked to me a lot about this product times ago. So I decided to try it. NB. This article is not yet finished so some typos can still be included or paragraph not yet formatted.","title":"About"},{"location":"IT/freeipa/#objectives","text":"Install a functional FreeIPA server to : manage users and groups Centralise User SSH keys Automount This is the first step, I will add new modules after FreeOTP","title":"Objectives"},{"location":"IT/freeipa/#requirements","text":"A CentOS machine (10G HD System, 1 VCPU, 2G RAM ) a local domain name like myplace.local","title":"Requirements"},{"location":"IT/freeipa/#references","text":"This article is based on : - FreeIPA - UnixMen","title":"References"},{"location":"IT/freeipa/#core-installation","text":"","title":"Core Installation"},{"location":"IT/freeipa/#prepare-the-machine","text":"Add your machine ip and name in your /etc/hosts file echo \"$(ip -o -4 addr show | grep -v \" lo\" | head -1 | awk {'print $4'} | cut -d'/' -f1) $(hostname) $(hostname -s)\" >> /etc/hosts That would add something like : 10.0.0.1 ipaserver.myplace.local ipaserver","title":"Prepare the machine"},{"location":"IT/freeipa/#install-the-software","text":"Install the requirements to setup everything : yum install ipa-server bind-dyndb-ldap ipa-server-dns Prepare the following infos before executing the install process : domain name (myplace.local) will be determined based on machine hostname, you just have to confirm it Directory Manager password IPA admin password A DNS Forwarder ipa-server-install --setup-dns Answer the questions At the end the following message will appear : Be sure to back up the CA certificates stored in /root/cacert.p12 These files are required to create replicas. The password for these files is the Directory Manager password Backup this file","title":"Install the software"},{"location":"IT/freeipa/#firewall","text":"if you want to use the local firewall on the centos, allow incoming traffic: firewall-cmd --permanent --add-service=ntp firewall-cmd --permanent --add-service=http firewall-cmd --permanent --add-service=https firewall-cmd --permanent --add-service=ldap firewall-cmd --permanent --add-service=ldaps firewall-cmd --permanent --add-service=kerberos firewall-cmd --permanent --add-service=kpasswd If you want to use your FreeIPA to hande also the PKI part, add the RootCA, located in /etc/ipa/ca.crt, in your firefox or system's CA.","title":"Firewall"},{"location":"IT/freeipa/#configure-freeipa","text":"Everything can be done through a web interface or commands lines. I will use command line. The web interface is reachable through https://ipaserver.myplace.local/","title":"Configure FreeIPA"},{"location":"IT/freeipa/#user-management","text":"A NFS Server will be used in order to have a unique point of storage for home dir. This will avoid to have multiple time the same data over multiple machine. The NFS Server will be a freebsd server with ZFS Storage.","title":"User Management"},{"location":"IT/freeipa/#nfs-mount-configuration-for-homedir","text":"On FreeIPA Server : ipaserver# ipa automountmap-add default auto.home Added automount map \"auto.home\" Map: auto.home ipaserver# ipa automountkey-add default --key \"/exports/home\" --info auto.home auto.master Added automount key \"/exports/home\" Key: /exports/home Mount information: auto.home ipaserver# ipa automountkey-add default --key \"*\" --info \"-fstype=nfs4,rw,sec=krb5,soft,rsize=8192,wsize=8192 nfssrv.myplace.local:/exports/home/&\" auto.home Added automount key \"*\" Key: * Mount information: -fstype=nfs4,rw,sec=krb5,soft,rsize=8192,wsize=8192 nfssrv.myplace.local:/exports/home/& On Linux machines ensure that home dir will be created automatically if it doesn't exist. authconfig --enablemkhomedir --update","title":"NFS Mount configuration for homedir"},{"location":"IT/freeipa/#linux","text":"","title":"Linux"},{"location":"IT/freeipa/#linux-nfs-server","text":"Source : https://blog.delouw.ch/2015/03/14/using-ipa-to-provide-automount-maps-for-nfsv4-home-directories/ Configure sssd + krb5.conf ipa service-add nfs/nfssrv.myplace.local ipa-getkeytab -s ipasrv.myplace.local -p nfs/nfssrv.myplace.local -k /etc/krb5.keytab","title":"Linux NFS Server"},{"location":"IT/freeipa/#linux-ipa-client","text":"ipa-server# ipa host-add ipaclient2.myplace.local --ip-address=A.B.C.D ipa-server# ipa service-add nfs/ipaclient2.myplace.local ipa-client# yum install ipa-client ipa-client# mkdir -p /exports/home ipa-client# authconfig --enablemkhomedir --update ipa-client# generate /etc/krb5.conf ipa-client# kinit ipa-client# ipa-getkeytab -s ipasrv.myplace.local -p nfs/${HOSTNAME} -k /etc/krb5.keytab ipa-client# ipa-client-install Or ipa-client# ipa-client-install --domain=myplace.local --server=ipaserver.myplace.local --realm=MYPLACE.LOCAL ipa-client# ipa-client-automount --location=default Ensure that a mount | grep auto return auto.home on /exports/home type autofs (rw,relatime,fd=18,pgrp=19004,timeout=300,minproto=5,maxproto=5,indirect) If not edit /etc/nsswitch.conf find the automount line, sss may be missing it should be like : automount: files sss Fix it, restart sssd and autofs.","title":"Linux IPA Client"},{"location":"IT/freeipa/#freebsd","text":"","title":"FreeBSD"},{"location":"IT/freeipa/#freebsd-nfs-server","text":"","title":"FreeBSD NFS Server"},{"location":"IT/freeipa/#freebsd-ipa-client","text":"Source : - https://blog.hostileadmin.com/2016/03/24/integrating-freebsd-w-freeipasssd/ - https://forums.freebsd.org/threads/46526/ On the FreeBSD Client (not yet functionnal) compile sssd with smb support and --with-krb5-conf=/etc/krb5.conf in sssd/Makefile (thx https://community.riocities.com/freebsd_nfv4_krb.html) mkdir -p /usr/compat/linux/proc echo \"linproc /usr/compat/linux/proc linprocfs rw 0 0\" >> /etc/fstab mkdir /var/log/krb5 edit /etc/pam.d/system on the FreeIPA Server ipa-host-add FREEBSD_FQDN ipa-getkeytab -s ${HOSTNAME} -p host/FREEBSD_FQDN -k copy the newly created keytab file to /etc/krb5.keytab on the FreeBSD Client Add TLS_CACERT /etc/ipa/ca.crt in /usr/local/etc/openldap/ldap.conf","title":"FreeBSD IPA Client"},{"location":"IT/freeipa/#allow-some-users-to-connect-through-ssh","text":"Based on http://www.freeipa.org/page/Howto/HBAC_and_allow_all Create a new rule name allow_ssh ipaserver# ipa hbacrule-add allow_ssh Added HBAC rule \"allow_ssh\" Rule name: allow_ssh Enabled: TRUE Associate newly created HBAC rule ipaserver# ipa hbacrule-add-service allow_ssh --hbacsvcs=sshd Rule name: allow_ssh Enabled: TRUE Services: sshd Number of members added 1 Associate a User to this rule ipaserver# ipa hbacrule-add-user allow_ssh --user=username_allowed Rule name: allow_ssh Enabled: TRUE Users: username_allowed Number of members added 1 ipaserver# ipa hbacrule-add-host allow_ssh --hosts=ipaclient.myplace.local Rule name: allow_ssh Enabled: TRUE Users: username_allowed Hosts: ipaclient.myplace.local Number of members added 1","title":"Allow some users to connect through ssh"},{"location":"IT/freeipa/#allow-some-users-to-excute-commands-with-sudo","text":"In the previous section about allowing ssh command, I've written the command output, but in the following one, I will not. Before allowing user to execute specific command through sudo, we need to allow the user to access sudo. ipaserver# ipa hbacrule-add allow_sudo ipaserver# ipa hbacrule-add-service allow_sudo --hbacsvcs=sudo ipaserver# ipa hbacrule-add-user allow_sudo --user=username_allowed ipaserver# ipa hbacrule-add-host allow_sudo --hosts=ipaclient.myplace.local Ok now let's allow the user execute a command like whoami. Beware that sssd is a caching system so I can take time to refresh the data (up to 6h) - Incrementally, meaning only changes to rules since the last full update (ldap_sudo_smart_refresh_interval, the time in seconds); the default is 15 minutes, - Fully, which dumps the entire caches and pulls in all of the current rules on the LDAP server(ldap_sudo_full_refresh_interval, the time in seconds); the default is six hours. Source sssd-ldap-sudo ipaserver# ipa sudorule-add whoami ipaserver# ipa sudocmd-add /usr/bin/whoami ipaserver# ipa sudorule-add-allow-command whoami --sudocmds /usr/bin/whoami ipaserver# ipa sudorule-add-host whoami --hosts ipaclient.myplace.local ipaserver# ipa sudorule-add-user whoami --users username_allowed Now if we want to allow to execute sudo whoami without autenticate the user we add this: ipaserver# ipa sudorule-add-option whoami --sudooption '!authenticate'","title":"Allow some users to excute commands with sudo"},{"location":"IT/linux-best-practices/","text":"Overall All those recommendations should be applied on servers and all environments (test, pre-production, production). It can be also used on dev environments. This document cover RHEL / Centos System and can be used for other unix systems If you ask why I wrote this document that's because still in this year of 2016, some people or companies doesn't ( want to know|know ) how to manage their IT !! Requirements Time Book some time to allow your IT team to do some labs, research keep inform about new technologies. They will take it as a deep breath, change their daily and give you some feedback about new product that can make your company : - more efficient - attractive - competitive - may be cheaper - avoid losing IT guys Hardware Having hardware for testing is mandatory, you should try to have a testing server for each model you have in production. Maybe you can use your spare and test it in the same time. It can sound like crazy but if you have multiple models in production you can't bet on the total compatibility or using another model as spare. Event if linux is stable, sometime some chipsets can react in different ways with the same OS baseline or with a different distribution, kernel flavor. Try to limit the HW model with two models a small one (1-2 CPUs) and a bigger one (1-4 CPUs). If you have any requirement about storage, think that it can be done on dedicated boxes (nexenta, freebsd zfs filer, emc2, netapp) or split over shards ( RedHat's ceph ) Software Support If you use Linux in production with commercial software and if you don't have any linux guru in your team, some companies provide support for their OS like : - RedHat - Suse - Oracle Other Linux distribution are supported by companies but not the editor. Support provide you contact with the editor for some debugging & security issues. They also provide in a short delay bug and security fixes on the version you use. Environment Make multiple environments !! Dev, Test, Qual, Production doesn't have the same architecture details and so SLA !! Infrastructure The following points are mostly important component for a complete infrastructure, following products are just examples and I'm or was used to work with. Managed gigabit switch (yeah monitoring bandwidth is helpful ...) Servers with a remote management console (iKVM, HP ILO, Dell iDrac) Monitoring on all the IT Infrastructure with monitoring software Reporting with JasperSoft , a free community edition is available. Inventory aka CMDB with GLPI & OCS Inventory Workflow Tools aka BPM Bonitasoft Versioning system ( GIT , also a big thanks to @cicatrice for introducing me to GOGS a lightweight central repository DNS (private and if required public) NTP LDAP Syslog concentrator system IP Address Management aka IPAM True Firewalls with true filtering rules and no allowing from ANY to ANY is not a valid rule Local mirror for OS, software, packages deployment to avoid using your internet connectivity bandwith when you deploy and update servers Automation Tools : OpenSource : The Foreman and Puppet , also grouped under a unique project named Katello Ansible Commercial : RedHat Satellite based on katello If you're asking why ansible and katello are both selected that's because they provide both services at different levels. DNS infrastructure Install a private DNS server to resolve internal and external zone (internet), and private NTP Server to sync your servers clock. As you will allow in your firewall rules, that all your infrastructure to connect to these servers put them in a DMZ not in your lan. If you can add a second servers it will increase the availability of the service. Warning Do not mix Public and Private DNS !! OS Installation As we are talking about servers, there is no graphical gui installed on it, only ssh access for a good old terminal. For those that are not familiar managing system with a terminal, this document can rude. Network Machines must have a FQDN based a name template model defined by the company or the team. Avoid to the maximum using public IP, Nat and Pat from public to private IP are working fine. Don't forget to define reverse IP, it will help in debugging some situations. Storage Split System & Data The system and data must be separated on different disk for many reason. - IO performance, as system disk can be slower as the performance is focus on apps - Cost, high performance disks are expensives do not use them for the system - If you need to move the data disk to another system it will not embed system parts System Partitions Based on a Centos 7 minimal install (~292 Packages) will consume around 1.2 GB, but we need a disk of 15G for whole system. This partition schema can be extended with LVM to fit requirements. Mount point Size Comment / 2G Root FS /boot 500M Boot partition /boot/efi 200M Uefi Partition (if machine configuration required it) /var 2G variable data /var/log 5G Logs partition /var/tmp 1G Tmp file storage that survive to a reboot /tmp 1G Tmp file storage that is cleaned during boot swap 2G Swap partition More information on Linux FS Hierarchy Danger This FS template is designed for a base system without any services. If you want to install any software like MySQL or Apache, some modifications are required. A home fs can be setup if you think that your users can store some data. Application Partitions You must use a or many dedicated disk(s) for your application. Also partition schema should be defined to avoid any \"surprise\" like : - Someone activated the debug mode and logfiles increases faster that you can handle - you're under attack - you don't rotate your logs regularly - you don't compress old logs, and you keep them on the server - your backup is using a lot of space and make the disk full - and lot more... You can use the following example. Mount point Size Comment /srv 100M applications root folder /srv/myapp 100M myapp root folder /srv/myapp/app XG where binaries and libraries are stored to run myapp application (tomcat, mysql...) /srv/myapp/data XG myapp data /srv/myapp/logs XG myapp logs /srv/myapp/tmp XG tmp folder for myapp /srv/myapp/backups XG backup folder for myapp You can also add sub partition under data, backups and logs if you have multiple application component and if you think it's better. Thank you @cicatrice for showing me /srv partition Packages Install only required packages nothing more !! The more package you install on the machine, the more you will need to patch / upgrade. First, you install the base system and in a second step a third party tool will deploy your required packages and configuration (Puppet, Chef, ...). This method will allow you to modify your base applications' requirements without changing your installation process and all your active machines will inherit the new packages in the same time. Also do not install any compiler on the server to avoid any security breach. It's also recommended avoiding installing software from archive or third party tool (install shell). Use the packaging system to deploy the software. Services Disable useless services like wpa_supplicant, dhcpd, iptables, ip6tables, ipv6 if you don't need them. They can be source of security breachs or false alerts. Users First you have to clearly understand that you have two kind of users : - physicals one aka human beings, coworkers, customers, providers - technicals one like apache, mysql... Technicals accounts should not be used with password auth in most of the cases. A sudo or ssh login should be enough. Try to have a centralized tools that allow to have a clear overview of which application use which techical account. In case of changing the password, you will not have a big surprise. Accounts Avoid defining physical users on servers at the maximum, you can use a centralized infrastructure like LDAP or AD to manage your users. Only technical or applicative users should be defined locally on the server like apache, mysql, ... Even technical or applicative account can be defined in the LDAP system as SSSD subsystem will keep a local cache in case your LDAP infra is down. If your User directory can be down for a time, create an account with sudo access to all commands, this account should be used only in case of emergency. Passwords If the passwords are managed locally. The users' password policy should be compliant with the company's policy. PAM can be used to check the password compliance with the policy when the password is defined. The major issue will be to distribute/synchronize the password to all machines. If the password is the same, it can be defined with a configuration management software. If you need to have a different password per server you will need to think it in a different way. Some configuration management software may allow you to use override default value, so per server or group of server the password can be overrided. Also, some software, mostly commercial, will allow you to manage from a central repository the password of your different account of the machine. They will also allow you to change them on a defined frequency. UID / GID In order to avoid any issues about software that have different uid/gid on different plateforme. Ensure to prepare a mapping for all applications (internals or provided by third party software provider). This will avoid issues about different uid/gid on machines Warning Beware of applicative account that will need credentials !! Also don't forget that when some from the IT leave the department or the company. Revoke immediately his access and change all passwords that he could have access! Manage the Server Connecting to the server Use SSHv2 and avoid any weak protocols like ssh1, telnet, rlogin (yes still used in 2016 in some companies...) Use standard account, direct root access should be used only in emergency. You can do most of the check as a standard user, and it will avoid any mistake. Use SUDO !!! You can use sudo to elevate your privileges and do some admin operations. But don't use sudo with a shell as parameter or \"sudo -s\" it will not help to trace who make some errors or destroyed data. Use a centralized configuration management Install a third party tool like puppet to allow you to : - ensure services are running or not - deploy configurations files - manage users - ensure systems inside a pool or a cluster are identical Manage your logs Logs must be rotated on a daily basis, logrotate can help you doing it. BTW logs must be also forwarded to a central point to avoid any deletion. CF ElasticSearch Logstash Kibana stack (ELK). Crontab Crontab should be created in the /etc/cron.d folder. This method allow centralizing crontab in a single folder with explicits filenames, just avoid very long filename. You should also deny access to the crontab for users, everything can be done in the /etc/cron.d folder. Also, as users couldn't create their own crontab they will have to go through a process to submit new crontab and avoid some mistake or overlap during time period (tasks during backups). Also, crontab must be redirected to a log file or to /dev/null, never in a local mailbox as they are never read, purged and can fill the associated FS. If some information must be sent by mail, make it in the script. Job Scheduler / Task Management Maybe using a Central Task Management system is a good idea instead of crons https://www.sos-berlin.com/ Release Management Use a Release Management product like RedHat Satellite (spacewalk in community). It will allow you to define multiple Channel Software Repository that are validated by IT Teams. Theses repository will be the source used on servers to install software from. With this process, until new version are pushed in Channels, the version will not change and all machine subscribed to this channels will have the same software release. You can manage as many channel as you want or need like : - Production RHEL 7 - Test (Future Production) RHEL 7 - Production HP Software - Your own software channel Also, this Release Management Software will help you in making snapshot of the server before any updates to do a rollback if some issues occurs. OS Tuning Network Linux Network Tuning 2013 IO Scheduler By default the IO scheduler is CFQ. CFQ CFQ places synchronous requests submitted by processes into a number of per-process queues and then allocates timeslices for each of the queues to access the disk. The length of the time slice and the number of requests a queue is allowed to submit depends on the I/O priority of the given process. Asynchronous requests for all processes are batched together in fewer queues, one per priority. While CFQ does not do explicit anticipatory I/O scheduling, it achieves the same effect of having good aggregate throughput for the system as a whole, by allowing a process queue to idle at the end of synchronous I/O thereby \"anticipating\" further close I/O from that process. It can be considered a natural extension of granting I/O time slices to a process. Warning source : CFQ Scheduler It can be change to the following : - noop recommended for SSD storage, and VM. The NOOP scheduler inserts all incoming I/O requests into a simple FIFO queue and implements request merging. This scheduler is useful when it has been determined that the host should not attempt to re-order requests based on the sector numbers contained therein. In other words, the scheduler assumes that the host is definitionally unaware of how to productively re-order requests. Danger Noop Scheduler deadline recommanded for hypervisor and other machines The main goal of the Deadline scheduler is to guarantee a start service time for a request.[1] It does so by imposing a deadline on all I/O operations to prevent starvation of requests. It also maintains two deadline queues, in addition to the sorted queues (both read and write). Deadline queues are basically sorted by their deadline (the expiration time), while the sorted queues are sorted by the sector number. Danger Deadline Scheduler Beware that depending on the storage and the hardware the results can be different with huge delta, like with fc and multipath. Another point to take care, is to test the infrastructure without any load in the same time to avoid any noise. To change it permanently : add \"elevator=noop\" to /boot/grub/menu.list in the corresponding kernel line like : kernel /vmlinuz-2.6.16.60-0.91.1-smp root=/dev/sysvg/root splash=silent splash=off showopts elevator=noop To change it dynamically : On a specific disk : echo \"scheduler_name\" > /sys/block/<Disk_Name>/queue/scheduler On all disks from emc: for disk in ` ls -1 /sys/block | egrep '^emc|^sd' ` ; do echo \"deadline\" > /sys/block/ $disk /queue/scheduler ; done Security Auditd With auditd you can track what happened to your server. Which user with which program remove this file ... But this tracking tool consume resources so use it with care (disk io and storage) Grub If you have access to the machine console (physical, remote or virtual), you can reboot and use /bin/bash as init process. With this trick you gain root access without any credentials. You need to secure grub with a password. Packages / Programs Do not install any compiler on the server. If some compilers are installed, and you can't uninstall them, make them unavailable to everyone. Raise alerts when packages are changes without any reason. Avoid any setuid root program / scripts. Any application that are executed on the server must be executed as another user than root except some product like apache that fork process directly with the good account. Do not execute as root scripts that can be modified by a user, they could gain root access. To keep tracks of changes on scripts deployed on your server use a versioning system (Git or SVN). A configuration management can push the new version automatically. Users Do not work as root or on the console when the machine is in maintenance mode ! Raise alerts when : - root is connected to the machine - same account is used from different locations - Failed login multiple time in a short time range and a long one. Filesystem Make /tmp, /var/tmp and data FS structure in non-executable mode. You can enhance with also - nodev \u2013 Do not allow character or special devices on this partition (prevents use of device files such as zero, sda etc). - nosuid - Do not set SUID/SGID access on this partition (prevent the setuid bit). Selinux If you do know about Selinux, use it, it will increase the security for the system and of the applications. If you don't know about it, do not activate it, it will block your applications. Password Policy Avoid using the same password on every machine. SSH SSH can be configured to use public key in a folder different from user's home. With this method only admins can allow a public key to connect to an account, but private key must not be shared !!! In the autorized_keys you can also set the ip source and the commands that are allowed to be executed. ex : from=\"1.2.3.4\",no-agent-forwarding,no-port-forwarding,no-X11-forwarding ssh-rsa ... Also remove the ssh1 compatibility. Files and Directory permissions Do not allow files and directory world writable !! Grand access to file and directory with acl or group permissions. Danger You can add some crontab to list files and dirs with world writable & setuid files Ctrl-Alt-Delete combinaison This key combination can be disabled in /etc/inittab to avoid any mistake on a KVM or in a console. Backups Do not backup the OS !! Backup only applications data and applications logs if they can't be forwarded to a central syslog. The OS can be reinstalled in less than 10' for a vm and 30' for a physical machine with some tools like foreman / puppet. All your configuration should be deployed by your configuration manager. Also don't forget to use a different location for your backup to avoid any surprise (cryptlocker) or mistake (delete on the backup share). Don't forget that backup is like schrodinger's cat, until your restore test you don't know if your backup are consistent. Danger Raid System is not a backup !! Monitoring Never forget that your monitoring tool should be open enough to allow to be configured through API or command lines. This will allow you to be flexible if you create machine or service on demand through an industrial mechanism. Capacity and availability local agent Here is short and not limited list of local tools that can help you : - ntop - htop - iotop - top - sar - tcpdump (remove it after debug to avoid security breach) remote monitoring SNMP (v2c or v3) Librenms Collectd Grafana Centreon Shinken Prometheus Nagios Cacti What should be monitored on a system You must monitor what is running on your machine. Availability System Process like - sshd - rsyslog - crond Capacity CPU (User, System, Free, IOWait) Memory (Total, Free, Cached, Shared, Swap) Load (Beware that the alerting should be adapted depending of #cpu on your machine) Storage (Threshold depends of your capacity 20% of free space on 1PB can be not as critical as on 1GB ) TCP Stack state What should be monitored on an application Availability Application process like - apache - mysql Capacity Storage (Threshold depends of your capacity 20% of free space on 1PB can be not as critical as on 1GB ) Application perf indicator (user connected, #queries, #transaction per second, jmx metrics) Batch Execution If you schedule some batch (cronjob, at command ...) don't forget to monitor their execution and results. IE: in centreon monitoring system you can create passive check that are feeded by nsca deamon. This nsca daemon is contacted by send_nsca command that give some status about a command linked to the previous check. With a check freshness define on the passive check, like 4h, if you don't have any feeback from the batch every 4h an alarm will raise. Log Management {% link \"Elastic Stack\" https://www.elastic.co/products%} formerly ElasticSearch, Logstash, Kibana. OpenSource product, Commercial Support available. Splunk (Commercial but Free for 500MB) HP Arcsight (commercial) Documentation Write any documentation related to your infrastructure. Create some generic documentation and procedure for the OS and core application (DB, tomcat ...) about : - managing the process and service - how standard are defined (password policy, partitioning, security... ) - network diagram to explain how your network / infrastructure are designed, this can help you investigate on problem and also give an overview for new comers. Specific documentation will explain the workflow of application about : - how data are pushed, pulled or received - how users connect to application - how application are related to others applications Don't forget that in most case a diagram is a better way to explain to someone instead of reading 100 pages of documentations. For creating diagram, Visio on MS platform is your friend, for Apple user use Omnigraffle. Both products are commercials but they worst it. Tools tmux or screen graphviz (quick and simple diagram) Grafana 3rd Party Required Tools Whiteboard !!!","title":"Linux Best Practices"},{"location":"IT/linux-best-practices/#overall","text":"All those recommendations should be applied on servers and all environments (test, pre-production, production). It can be also used on dev environments. This document cover RHEL / Centos System and can be used for other unix systems If you ask why I wrote this document that's because still in this year of 2016, some people or companies doesn't ( want to know|know ) how to manage their IT !!","title":"Overall"},{"location":"IT/linux-best-practices/#requirements","text":"","title":"Requirements"},{"location":"IT/linux-best-practices/#time","text":"Book some time to allow your IT team to do some labs, research keep inform about new technologies. They will take it as a deep breath, change their daily and give you some feedback about new product that can make your company : - more efficient - attractive - competitive - may be cheaper - avoid losing IT guys","title":"Time"},{"location":"IT/linux-best-practices/#hardware","text":"Having hardware for testing is mandatory, you should try to have a testing server for each model you have in production. Maybe you can use your spare and test it in the same time. It can sound like crazy but if you have multiple models in production you can't bet on the total compatibility or using another model as spare. Event if linux is stable, sometime some chipsets can react in different ways with the same OS baseline or with a different distribution, kernel flavor. Try to limit the HW model with two models a small one (1-2 CPUs) and a bigger one (1-4 CPUs). If you have any requirement about storage, think that it can be done on dedicated boxes (nexenta, freebsd zfs filer, emc2, netapp) or split over shards ( RedHat's ceph )","title":"Hardware"},{"location":"IT/linux-best-practices/#software","text":"","title":"Software"},{"location":"IT/linux-best-practices/#support","text":"If you use Linux in production with commercial software and if you don't have any linux guru in your team, some companies provide support for their OS like : - RedHat - Suse - Oracle Other Linux distribution are supported by companies but not the editor. Support provide you contact with the editor for some debugging & security issues. They also provide in a short delay bug and security fixes on the version you use.","title":"Support"},{"location":"IT/linux-best-practices/#environment","text":"Make multiple environments !! Dev, Test, Qual, Production doesn't have the same architecture details and so SLA !!","title":"Environment"},{"location":"IT/linux-best-practices/#infrastructure","text":"The following points are mostly important component for a complete infrastructure, following products are just examples and I'm or was used to work with. Managed gigabit switch (yeah monitoring bandwidth is helpful ...) Servers with a remote management console (iKVM, HP ILO, Dell iDrac) Monitoring on all the IT Infrastructure with monitoring software Reporting with JasperSoft , a free community edition is available. Inventory aka CMDB with GLPI & OCS Inventory Workflow Tools aka BPM Bonitasoft Versioning system ( GIT , also a big thanks to @cicatrice for introducing me to GOGS a lightweight central repository DNS (private and if required public) NTP LDAP Syslog concentrator system IP Address Management aka IPAM True Firewalls with true filtering rules and no allowing from ANY to ANY is not a valid rule Local mirror for OS, software, packages deployment to avoid using your internet connectivity bandwith when you deploy and update servers Automation Tools : OpenSource : The Foreman and Puppet , also grouped under a unique project named Katello Ansible Commercial : RedHat Satellite based on katello If you're asking why ansible and katello are both selected that's because they provide both services at different levels.","title":"Infrastructure"},{"location":"IT/linux-best-practices/#dns-infrastructure","text":"Install a private DNS server to resolve internal and external zone (internet), and private NTP Server to sync your servers clock. As you will allow in your firewall rules, that all your infrastructure to connect to these servers put them in a DMZ not in your lan. If you can add a second servers it will increase the availability of the service. Warning Do not mix Public and Private DNS !!","title":"DNS infrastructure"},{"location":"IT/linux-best-practices/#os-installation","text":"As we are talking about servers, there is no graphical gui installed on it, only ssh access for a good old terminal. For those that are not familiar managing system with a terminal, this document can rude.","title":"OS Installation"},{"location":"IT/linux-best-practices/#network","text":"Machines must have a FQDN based a name template model defined by the company or the team. Avoid to the maximum using public IP, Nat and Pat from public to private IP are working fine. Don't forget to define reverse IP, it will help in debugging some situations.","title":"Network"},{"location":"IT/linux-best-practices/#storage","text":"","title":"Storage"},{"location":"IT/linux-best-practices/#split-system-data","text":"The system and data must be separated on different disk for many reason. - IO performance, as system disk can be slower as the performance is focus on apps - Cost, high performance disks are expensives do not use them for the system - If you need to move the data disk to another system it will not embed system parts","title":"Split System &amp; Data"},{"location":"IT/linux-best-practices/#system-partitions","text":"Based on a Centos 7 minimal install (~292 Packages) will consume around 1.2 GB, but we need a disk of 15G for whole system. This partition schema can be extended with LVM to fit requirements. Mount point Size Comment / 2G Root FS /boot 500M Boot partition /boot/efi 200M Uefi Partition (if machine configuration required it) /var 2G variable data /var/log 5G Logs partition /var/tmp 1G Tmp file storage that survive to a reboot /tmp 1G Tmp file storage that is cleaned during boot swap 2G Swap partition More information on Linux FS Hierarchy Danger This FS template is designed for a base system without any services. If you want to install any software like MySQL or Apache, some modifications are required. A home fs can be setup if you think that your users can store some data.","title":"System Partitions"},{"location":"IT/linux-best-practices/#application-partitions","text":"You must use a or many dedicated disk(s) for your application. Also partition schema should be defined to avoid any \"surprise\" like : - Someone activated the debug mode and logfiles increases faster that you can handle - you're under attack - you don't rotate your logs regularly - you don't compress old logs, and you keep them on the server - your backup is using a lot of space and make the disk full - and lot more... You can use the following example. Mount point Size Comment /srv 100M applications root folder /srv/myapp 100M myapp root folder /srv/myapp/app XG where binaries and libraries are stored to run myapp application (tomcat, mysql...) /srv/myapp/data XG myapp data /srv/myapp/logs XG myapp logs /srv/myapp/tmp XG tmp folder for myapp /srv/myapp/backups XG backup folder for myapp You can also add sub partition under data, backups and logs if you have multiple application component and if you think it's better. Thank you @cicatrice for showing me /srv partition","title":"Application Partitions"},{"location":"IT/linux-best-practices/#packages","text":"Install only required packages nothing more !! The more package you install on the machine, the more you will need to patch / upgrade. First, you install the base system and in a second step a third party tool will deploy your required packages and configuration (Puppet, Chef, ...). This method will allow you to modify your base applications' requirements without changing your installation process and all your active machines will inherit the new packages in the same time. Also do not install any compiler on the server to avoid any security breach. It's also recommended avoiding installing software from archive or third party tool (install shell). Use the packaging system to deploy the software.","title":"Packages"},{"location":"IT/linux-best-practices/#services","text":"Disable useless services like wpa_supplicant, dhcpd, iptables, ip6tables, ipv6 if you don't need them. They can be source of security breachs or false alerts.","title":"Services"},{"location":"IT/linux-best-practices/#users","text":"First you have to clearly understand that you have two kind of users : - physicals one aka human beings, coworkers, customers, providers - technicals one like apache, mysql... Technicals accounts should not be used with password auth in most of the cases. A sudo or ssh login should be enough. Try to have a centralized tools that allow to have a clear overview of which application use which techical account. In case of changing the password, you will not have a big surprise.","title":"Users"},{"location":"IT/linux-best-practices/#accounts","text":"Avoid defining physical users on servers at the maximum, you can use a centralized infrastructure like LDAP or AD to manage your users. Only technical or applicative users should be defined locally on the server like apache, mysql, ... Even technical or applicative account can be defined in the LDAP system as SSSD subsystem will keep a local cache in case your LDAP infra is down. If your User directory can be down for a time, create an account with sudo access to all commands, this account should be used only in case of emergency.","title":"Accounts"},{"location":"IT/linux-best-practices/#passwords","text":"If the passwords are managed locally. The users' password policy should be compliant with the company's policy. PAM can be used to check the password compliance with the policy when the password is defined. The major issue will be to distribute/synchronize the password to all machines. If the password is the same, it can be defined with a configuration management software. If you need to have a different password per server you will need to think it in a different way. Some configuration management software may allow you to use override default value, so per server or group of server the password can be overrided. Also, some software, mostly commercial, will allow you to manage from a central repository the password of your different account of the machine. They will also allow you to change them on a defined frequency.","title":"Passwords"},{"location":"IT/linux-best-practices/#uid-gid","text":"In order to avoid any issues about software that have different uid/gid on different plateforme. Ensure to prepare a mapping for all applications (internals or provided by third party software provider). This will avoid issues about different uid/gid on machines Warning Beware of applicative account that will need credentials !! Also don't forget that when some from the IT leave the department or the company. Revoke immediately his access and change all passwords that he could have access!","title":"UID / GID"},{"location":"IT/linux-best-practices/#manage-the-server","text":"","title":"Manage the Server"},{"location":"IT/linux-best-practices/#connecting-to-the-server","text":"Use SSHv2 and avoid any weak protocols like ssh1, telnet, rlogin (yes still used in 2016 in some companies...) Use standard account, direct root access should be used only in emergency. You can do most of the check as a standard user, and it will avoid any mistake.","title":"Connecting to the server"},{"location":"IT/linux-best-practices/#use-sudo","text":"You can use sudo to elevate your privileges and do some admin operations. But don't use sudo with a shell as parameter or \"sudo -s\" it will not help to trace who make some errors or destroyed data.","title":"Use SUDO !!!"},{"location":"IT/linux-best-practices/#use-a-centralized-configuration-management","text":"Install a third party tool like puppet to allow you to : - ensure services are running or not - deploy configurations files - manage users - ensure systems inside a pool or a cluster are identical","title":"Use a centralized configuration management"},{"location":"IT/linux-best-practices/#manage-your-logs","text":"Logs must be rotated on a daily basis, logrotate can help you doing it. BTW logs must be also forwarded to a central point to avoid any deletion. CF ElasticSearch Logstash Kibana stack (ELK).","title":"Manage your logs"},{"location":"IT/linux-best-practices/#crontab","text":"Crontab should be created in the /etc/cron.d folder. This method allow centralizing crontab in a single folder with explicits filenames, just avoid very long filename. You should also deny access to the crontab for users, everything can be done in the /etc/cron.d folder. Also, as users couldn't create their own crontab they will have to go through a process to submit new crontab and avoid some mistake or overlap during time period (tasks during backups). Also, crontab must be redirected to a log file or to /dev/null, never in a local mailbox as they are never read, purged and can fill the associated FS. If some information must be sent by mail, make it in the script.","title":"Crontab"},{"location":"IT/linux-best-practices/#job-scheduler-task-management","text":"Maybe using a Central Task Management system is a good idea instead of crons https://www.sos-berlin.com/","title":"Job Scheduler / Task Management"},{"location":"IT/linux-best-practices/#release-management","text":"Use a Release Management product like RedHat Satellite (spacewalk in community). It will allow you to define multiple Channel Software Repository that are validated by IT Teams. Theses repository will be the source used on servers to install software from. With this process, until new version are pushed in Channels, the version will not change and all machine subscribed to this channels will have the same software release. You can manage as many channel as you want or need like : - Production RHEL 7 - Test (Future Production) RHEL 7 - Production HP Software - Your own software channel Also, this Release Management Software will help you in making snapshot of the server before any updates to do a rollback if some issues occurs.","title":"Release Management"},{"location":"IT/linux-best-practices/#os-tuning","text":"","title":"OS Tuning"},{"location":"IT/linux-best-practices/#network_1","text":"Linux Network Tuning 2013","title":"Network"},{"location":"IT/linux-best-practices/#io-scheduler","text":"By default the IO scheduler is CFQ. CFQ CFQ places synchronous requests submitted by processes into a number of per-process queues and then allocates timeslices for each of the queues to access the disk. The length of the time slice and the number of requests a queue is allowed to submit depends on the I/O priority of the given process. Asynchronous requests for all processes are batched together in fewer queues, one per priority. While CFQ does not do explicit anticipatory I/O scheduling, it achieves the same effect of having good aggregate throughput for the system as a whole, by allowing a process queue to idle at the end of synchronous I/O thereby \"anticipating\" further close I/O from that process. It can be considered a natural extension of granting I/O time slices to a process. Warning source : CFQ Scheduler It can be change to the following : - noop recommended for SSD storage, and VM. The NOOP scheduler inserts all incoming I/O requests into a simple FIFO queue and implements request merging. This scheduler is useful when it has been determined that the host should not attempt to re-order requests based on the sector numbers contained therein. In other words, the scheduler assumes that the host is definitionally unaware of how to productively re-order requests. Danger Noop Scheduler deadline recommanded for hypervisor and other machines The main goal of the Deadline scheduler is to guarantee a start service time for a request.[1] It does so by imposing a deadline on all I/O operations to prevent starvation of requests. It also maintains two deadline queues, in addition to the sorted queues (both read and write). Deadline queues are basically sorted by their deadline (the expiration time), while the sorted queues are sorted by the sector number. Danger Deadline Scheduler Beware that depending on the storage and the hardware the results can be different with huge delta, like with fc and multipath. Another point to take care, is to test the infrastructure without any load in the same time to avoid any noise. To change it permanently : add \"elevator=noop\" to /boot/grub/menu.list in the corresponding kernel line like : kernel /vmlinuz-2.6.16.60-0.91.1-smp root=/dev/sysvg/root splash=silent splash=off showopts elevator=noop To change it dynamically : On a specific disk : echo \"scheduler_name\" > /sys/block/<Disk_Name>/queue/scheduler On all disks from emc: for disk in ` ls -1 /sys/block | egrep '^emc|^sd' ` ; do echo \"deadline\" > /sys/block/ $disk /queue/scheduler ; done","title":"IO Scheduler"},{"location":"IT/linux-best-practices/#security","text":"","title":"Security"},{"location":"IT/linux-best-practices/#auditd","text":"With auditd you can track what happened to your server. Which user with which program remove this file ... But this tracking tool consume resources so use it with care (disk io and storage)","title":"Auditd"},{"location":"IT/linux-best-practices/#grub","text":"If you have access to the machine console (physical, remote or virtual), you can reboot and use /bin/bash as init process. With this trick you gain root access without any credentials. You need to secure grub with a password.","title":"Grub"},{"location":"IT/linux-best-practices/#packages-programs","text":"Do not install any compiler on the server. If some compilers are installed, and you can't uninstall them, make them unavailable to everyone. Raise alerts when packages are changes without any reason. Avoid any setuid root program / scripts. Any application that are executed on the server must be executed as another user than root except some product like apache that fork process directly with the good account. Do not execute as root scripts that can be modified by a user, they could gain root access. To keep tracks of changes on scripts deployed on your server use a versioning system (Git or SVN). A configuration management can push the new version automatically.","title":"Packages / Programs"},{"location":"IT/linux-best-practices/#users_1","text":"Do not work as root or on the console when the machine is in maintenance mode ! Raise alerts when : - root is connected to the machine - same account is used from different locations - Failed login multiple time in a short time range and a long one.","title":"Users"},{"location":"IT/linux-best-practices/#filesystem","text":"Make /tmp, /var/tmp and data FS structure in non-executable mode. You can enhance with also - nodev \u2013 Do not allow character or special devices on this partition (prevents use of device files such as zero, sda etc). - nosuid - Do not set SUID/SGID access on this partition (prevent the setuid bit).","title":"Filesystem"},{"location":"IT/linux-best-practices/#selinux","text":"If you do know about Selinux, use it, it will increase the security for the system and of the applications. If you don't know about it, do not activate it, it will block your applications.","title":"Selinux"},{"location":"IT/linux-best-practices/#password-policy","text":"Avoid using the same password on every machine.","title":"Password Policy"},{"location":"IT/linux-best-practices/#ssh","text":"SSH can be configured to use public key in a folder different from user's home. With this method only admins can allow a public key to connect to an account, but private key must not be shared !!! In the autorized_keys you can also set the ip source and the commands that are allowed to be executed. ex : from=\"1.2.3.4\",no-agent-forwarding,no-port-forwarding,no-X11-forwarding ssh-rsa ... Also remove the ssh1 compatibility.","title":"SSH"},{"location":"IT/linux-best-practices/#files-and-directory-permissions","text":"Do not allow files and directory world writable !! Grand access to file and directory with acl or group permissions. Danger You can add some crontab to list files and dirs with world writable & setuid files","title":"Files and Directory permissions"},{"location":"IT/linux-best-practices/#ctrl-alt-delete-combinaison","text":"This key combination can be disabled in /etc/inittab to avoid any mistake on a KVM or in a console.","title":"Ctrl-Alt-Delete combinaison"},{"location":"IT/linux-best-practices/#backups","text":"Do not backup the OS !! Backup only applications data and applications logs if they can't be forwarded to a central syslog. The OS can be reinstalled in less than 10' for a vm and 30' for a physical machine with some tools like foreman / puppet. All your configuration should be deployed by your configuration manager. Also don't forget to use a different location for your backup to avoid any surprise (cryptlocker) or mistake (delete on the backup share). Don't forget that backup is like schrodinger's cat, until your restore test you don't know if your backup are consistent. Danger Raid System is not a backup !!","title":"Backups"},{"location":"IT/linux-best-practices/#monitoring","text":"Never forget that your monitoring tool should be open enough to allow to be configured through API or command lines. This will allow you to be flexible if you create machine or service on demand through an industrial mechanism.","title":"Monitoring"},{"location":"IT/linux-best-practices/#capacity-and-availability","text":"","title":"Capacity and availability"},{"location":"IT/linux-best-practices/#local-agent","text":"Here is short and not limited list of local tools that can help you : - ntop - htop - iotop - top - sar - tcpdump (remove it after debug to avoid security breach)","title":"local agent"},{"location":"IT/linux-best-practices/#remote-monitoring","text":"SNMP (v2c or v3) Librenms Collectd Grafana Centreon Shinken Prometheus Nagios Cacti","title":"remote monitoring"},{"location":"IT/linux-best-practices/#what-should-be-monitored-on-a-system","text":"You must monitor what is running on your machine.","title":"What should be monitored on a system"},{"location":"IT/linux-best-practices/#availability","text":"System Process like - sshd - rsyslog - crond","title":"Availability"},{"location":"IT/linux-best-practices/#capacity","text":"CPU (User, System, Free, IOWait) Memory (Total, Free, Cached, Shared, Swap) Load (Beware that the alerting should be adapted depending of #cpu on your machine) Storage (Threshold depends of your capacity 20% of free space on 1PB can be not as critical as on 1GB ) TCP Stack state","title":"Capacity"},{"location":"IT/linux-best-practices/#what-should-be-monitored-on-an-application","text":"","title":"What should be monitored on an application"},{"location":"IT/linux-best-practices/#availability_1","text":"Application process like - apache - mysql","title":"Availability"},{"location":"IT/linux-best-practices/#capacity_1","text":"Storage (Threshold depends of your capacity 20% of free space on 1PB can be not as critical as on 1GB ) Application perf indicator (user connected, #queries, #transaction per second, jmx metrics)","title":"Capacity"},{"location":"IT/linux-best-practices/#batch-execution","text":"If you schedule some batch (cronjob, at command ...) don't forget to monitor their execution and results. IE: in centreon monitoring system you can create passive check that are feeded by nsca deamon. This nsca daemon is contacted by send_nsca command that give some status about a command linked to the previous check. With a check freshness define on the passive check, like 4h, if you don't have any feeback from the batch every 4h an alarm will raise.","title":"Batch Execution"},{"location":"IT/linux-best-practices/#log-management","text":"{% link \"Elastic Stack\" https://www.elastic.co/products%} formerly ElasticSearch, Logstash, Kibana. OpenSource product, Commercial Support available. Splunk (Commercial but Free for 500MB) HP Arcsight (commercial)","title":"Log Management"},{"location":"IT/linux-best-practices/#documentation","text":"Write any documentation related to your infrastructure. Create some generic documentation and procedure for the OS and core application (DB, tomcat ...) about : - managing the process and service - how standard are defined (password policy, partitioning, security... ) - network diagram to explain how your network / infrastructure are designed, this can help you investigate on problem and also give an overview for new comers. Specific documentation will explain the workflow of application about : - how data are pushed, pulled or received - how users connect to application - how application are related to others applications Don't forget that in most case a diagram is a better way to explain to someone instead of reading 100 pages of documentations. For creating diagram, Visio on MS platform is your friend, for Apple user use Omnigraffle. Both products are commercials but they worst it.","title":"Documentation"},{"location":"IT/linux-best-practices/#tools","text":"tmux or screen graphviz (quick and simple diagram) Grafana","title":"Tools"},{"location":"IT/linux-best-practices/#3rd-party-required-tools","text":"Whiteboard !!!","title":"3rd Party Required Tools"},{"location":"IT/FreeIPA/","text":"FreeIPA Introduction About In order to make my infrastructure more easy to manage, I decide to install a FreeIPA server. One of my former colleague and now friend talk me a lot about this product times ago. So I decided to try it. NB. This article is not finish yet, so some typos can still be included or paragraph not yet formatted. Objectives Install a functional FreeIPA server to: manage users, groups, automount centralise ssh user public keys This is the first step, I will add new modules like FreeOTP Requirements a CentOS machine (10G HD System, 1 VCPU, 2G RAM ) a local domain name like myplace.local References This article is base on: FreeIPA UnixMen Core Installation Prepare the machine Add your machine ip and name in your /etc/hosts file echo \"$(ip -o -4 addr show | grep -v \" lo\" | head -1 | awk {'print $4'} | cut -d'/' -f1) $(hostname) $(hostname -s)\" >> /etc/hosts That would add something like : 10.0.0.1 ipaserver.myplace.local ipaserver Install the software Install the requirements to set up everything : yum install ipa-server bind-dyndb-ldap ipa-server-dns Prepare the following infos before executing the installation process: domain name (myplace.local) will be determined based on machine hostname, you just have to confirm it Directory Manager password IPA admin password A DNS Forwarder Then execute the following command and answer the questions ipa-server-install --setup-dns At the end the following message will appear : Be sure to back up the CA certificates stored in /root/cacert.p12 These files are required to create replicas. The password for these files is the Directory Manager password Backup this file !! Firewall if you want to use the local firewall on the centos, allow incoming traffic: firewall-cmd --permanent --add-service=ntp firewall-cmd --permanent --add-service=http firewall-cmd --permanent --add-service=https firewall-cmd --permanent --add-service=ldap firewall-cmd --permanent --add-service=ldaps firewall-cmd --permanent --add-service=kerberos firewall-cmd --permanent --add-service=kpasswd If you want to use your FreeIPA to handle also the PKI part, add the RootCA, located in /etc/ipa/ca.crt, in your firefox or system's CA. Configure FreeIPA Everything can be done through a web interface or commands lines. I will use command line. The web interface is reachable through https://ipaserver.myplace.local/ User Management A NFS Server will be used in order to have a unique point of storage for homedir. This will avoid multiple time the same data over multiple machine. The NFS Server will be a freebsd server with ZFS Storage. NFS Mount configuration for homedir On FreeIPA Server execute the following command: ipa automountmap-add default auto.home Added automount map \"auto.home\" Map: auto.home ipaserver# ipa automountkey-add default --key \"/exports/home\" --info auto.home auto.master Added automount key \"/exports/home\" Key: /exports/home Mount information: auto.home ipaserver# ipa automountkey-add default --key \"*\" --info \"-fstype=nfs4,rw,sec=krb5,soft,rsize=8192,wsize=8192 nfssrv.myplace.local:/exports/home/&\" auto.home Added automount key \"*\" Key: * Mount information: -fstype=nfs4,rw,sec=krb5,soft,rsize=8192,wsize=8192 nfssrv.myplace.local:/exports/home/& On Linux machines ensure that home dir will be created automatically if it doesn't exist. authconfig --enablemkhomedir --update Linux Linux NFS Server Source : blog delouw Configure sssd + krb5.conf ipa service-add nfs/nfssrv.myplace.local ipa-getkeytab -s ipasrv.myplace.local -p nfs/nfssrv.myplace.local -k /etc/krb5.keytab Linux IPA Client ipa-server# ipa host-add ipaclient2.myplace.local --ip-address=A.B.C.D ipa-server# ipa service-add nfs/ipaclient2.myplace.local ipa-client# yum install ipa-client ipa-client# mkdir -p /exports/home ipa-client# authconfig --enablemkhomedir --update ipa-client# generate /etc/krb5.conf ipa-client# kinit ipa-client# ipa-getkeytab -s ipasrv.myplace.local -p nfs/${HOSTNAME} -k /etc/krb5.keytab Then : ipa-client# ipa-client-install Or ipa-client# ipa-client-install --domain=myplace.local --server=ipaserver.myplace.local --realm=MYPLACE.LOCAL To finish with: ipa-client# ipa-client-automount --location=default Ensure that the automount is working execute the following command: mount | grep auto The result should be like : auto.home on /exports/home type autofs (rw,relatime,fd=18,pgrp=19004,timeout=300,minproto=5,maxproto=5,indirect) If not edit /etc/nsswitch.conf find the automount line, sss may be missing it should be like : automount: files sss Fix it, restart sssd and autofs. FreeBSD FreeBSD NFS Server FreeBSD IPA Client Source : - https://blog.hostileadmin.com/2016/03/24/integrating-freebsd-w-freeipasssd/ - https://forums.freebsd.org/threads/46526/ On the FreeBSD Client (not yet functional), compile sssd with smb support Edit sssd/Makefile and add the option --with-krb5-conf=/etc/krb5.conf (thx https://community.riocities.com/freebsd_nfv4_krb.html) freebsd_srv# mkdir -p /usr/compat/linux/proc freebsd_srv# echo \"linproc /usr/compat/linux/proc linprocfs rw 0 0\" >> /etc/fstab mkdir /var/log/krb5 edit /etc/pam.d/system TBF On the FreeIPA Server execute the following commands ipaserver# ipa-host-add FREEBSD_FQDN ipaserver# ipa-getkeytab -s ${HOSTNAME} -p host/FREEBSD_FQDN -k <location to export the keytab> Now, copy the newly created keytab file to /etc/krb5.keytab on the FreeBSD Client Add TLS_CACERT /etc/ipa/ca.crt in /usr/local/etc/openldap/ldap.conf Rules Allow some users to connect throught ssh Based on http://www.freeipa.org/page/Howto/HBAC_and_allow_all Create a new rule name allow_ssh ipaserver# ipa hbacrule-add allow_ssh Added HBAC rule \"allow_ssh\" Rule name: allow_ssh Enabled: TRUE Associate newly created HBAC rule ipaserver# ipa hbacrule-add-service allow_ssh --hbacsvcs=sshd Rule name: allow_ssh Enabled: TRUE Services: sshd Number of members added 1 Associate a User to this rule ipaserver# ipa hbacrule-add-user allow_ssh --user=username_allowed Rule name: allow_ssh Enabled: TRUE Users: username_allowed Number of members added 1 ipaserver# ipa hbacrule-add-host allow_ssh --hosts=ipaclient.myplace.local Rule name: allow_ssh Enabled: TRUE Users: username_allowed Hosts: ipaclient.myplace.local Number of members added 1 Allow some users to excute commands with sudo In the previous section about allowing ssh command, I've written the command output, but in the following one, I will not. Before allowing user to execute specific command through sudo, we need to allow the user to access sudo. ipaserver# ipa hbacrule-add allow_sudo ipaserver# ipa hbacrule-add-service allow_sudo --hbacsvcs=sudo ipaserver# ipa hbacrule-add-user allow_sudo --user=username_allowed ipaserver# ipa hbacrule-add-host allow_sudo --hosts=ipaclient.myplace.local Ok now let's allow the user execute a command like whoami. Beware that sssd is a caching system, so I can take time to refresh the data (up to 6h) - Incrementally, meaning only changes to rule since the last full update (ldap_sudo_smart_refresh_interval, the time in seconds); the default is 15 minutes, - Fully, which dumps the entire caches and pulls all the current rules on the LDAP server(ldap_sudo_full_refresh_interval, the time in seconds); the default is six hours. Source sssd-ldap-sudo ipaserver# ipa sudorule-add whoami ipaserver# ipa sudocmd-add /usr/bin/whoami ipaserver# ipa sudorule-add-allow-command whoami --sudocmds /usr/bin/whoami ipaserver# ipa sudorule-add-host whoami --hosts ipaclient.myplace.local ipaserver# ipa sudorule-add-user whoami --users username_allowed Now if we want to allow executing sudo whoami without autenticate the user we add this: ipaserver# ipa sudorule-add-option whoami --sudooption '!authenticate'","title":"FreeIPA Introduction"},{"location":"IT/FreeIPA/#freeipa-introduction","text":"","title":"FreeIPA Introduction"},{"location":"IT/FreeIPA/#about","text":"In order to make my infrastructure more easy to manage, I decide to install a FreeIPA server. One of my former colleague and now friend talk me a lot about this product times ago. So I decided to try it. NB. This article is not finish yet, so some typos can still be included or paragraph not yet formatted.","title":"About"},{"location":"IT/FreeIPA/#objectives","text":"Install a functional FreeIPA server to: manage users, groups, automount centralise ssh user public keys This is the first step, I will add new modules like FreeOTP","title":"Objectives"},{"location":"IT/FreeIPA/#requirements","text":"a CentOS machine (10G HD System, 1 VCPU, 2G RAM ) a local domain name like myplace.local","title":"Requirements"},{"location":"IT/FreeIPA/#references","text":"This article is base on: FreeIPA UnixMen","title":"References"},{"location":"IT/FreeIPA/#core-installation","text":"","title":"Core Installation"},{"location":"IT/FreeIPA/#prepare-the-machine","text":"Add your machine ip and name in your /etc/hosts file echo \"$(ip -o -4 addr show | grep -v \" lo\" | head -1 | awk {'print $4'} | cut -d'/' -f1) $(hostname) $(hostname -s)\" >> /etc/hosts That would add something like : 10.0.0.1 ipaserver.myplace.local ipaserver","title":"Prepare the machine"},{"location":"IT/FreeIPA/#install-the-software","text":"Install the requirements to set up everything : yum install ipa-server bind-dyndb-ldap ipa-server-dns Prepare the following infos before executing the installation process: domain name (myplace.local) will be determined based on machine hostname, you just have to confirm it Directory Manager password IPA admin password A DNS Forwarder Then execute the following command and answer the questions ipa-server-install --setup-dns At the end the following message will appear : Be sure to back up the CA certificates stored in /root/cacert.p12 These files are required to create replicas. The password for these files is the Directory Manager password Backup this file !!","title":"Install the software"},{"location":"IT/FreeIPA/#firewall","text":"if you want to use the local firewall on the centos, allow incoming traffic: firewall-cmd --permanent --add-service=ntp firewall-cmd --permanent --add-service=http firewall-cmd --permanent --add-service=https firewall-cmd --permanent --add-service=ldap firewall-cmd --permanent --add-service=ldaps firewall-cmd --permanent --add-service=kerberos firewall-cmd --permanent --add-service=kpasswd If you want to use your FreeIPA to handle also the PKI part, add the RootCA, located in /etc/ipa/ca.crt, in your firefox or system's CA.","title":"Firewall"},{"location":"IT/FreeIPA/#configure-freeipa","text":"Everything can be done through a web interface or commands lines. I will use command line. The web interface is reachable through https://ipaserver.myplace.local/","title":"Configure FreeIPA"},{"location":"IT/FreeIPA/#user-management","text":"A NFS Server will be used in order to have a unique point of storage for homedir. This will avoid multiple time the same data over multiple machine. The NFS Server will be a freebsd server with ZFS Storage.","title":"User Management"},{"location":"IT/FreeIPA/#nfs-mount-configuration-for-homedir","text":"On FreeIPA Server execute the following command: ipa automountmap-add default auto.home Added automount map \"auto.home\" Map: auto.home ipaserver# ipa automountkey-add default --key \"/exports/home\" --info auto.home auto.master Added automount key \"/exports/home\" Key: /exports/home Mount information: auto.home ipaserver# ipa automountkey-add default --key \"*\" --info \"-fstype=nfs4,rw,sec=krb5,soft,rsize=8192,wsize=8192 nfssrv.myplace.local:/exports/home/&\" auto.home Added automount key \"*\" Key: * Mount information: -fstype=nfs4,rw,sec=krb5,soft,rsize=8192,wsize=8192 nfssrv.myplace.local:/exports/home/& On Linux machines ensure that home dir will be created automatically if it doesn't exist. authconfig --enablemkhomedir --update","title":"NFS Mount configuration for homedir"},{"location":"IT/FreeIPA/#linux","text":"","title":"Linux"},{"location":"IT/FreeIPA/#linux-nfs-server","text":"Source : blog delouw Configure sssd + krb5.conf ipa service-add nfs/nfssrv.myplace.local ipa-getkeytab -s ipasrv.myplace.local -p nfs/nfssrv.myplace.local -k /etc/krb5.keytab","title":"Linux NFS Server"},{"location":"IT/FreeIPA/#linux-ipa-client","text":"ipa-server# ipa host-add ipaclient2.myplace.local --ip-address=A.B.C.D ipa-server# ipa service-add nfs/ipaclient2.myplace.local ipa-client# yum install ipa-client ipa-client# mkdir -p /exports/home ipa-client# authconfig --enablemkhomedir --update ipa-client# generate /etc/krb5.conf ipa-client# kinit ipa-client# ipa-getkeytab -s ipasrv.myplace.local -p nfs/${HOSTNAME} -k /etc/krb5.keytab Then : ipa-client# ipa-client-install Or ipa-client# ipa-client-install --domain=myplace.local --server=ipaserver.myplace.local --realm=MYPLACE.LOCAL To finish with: ipa-client# ipa-client-automount --location=default Ensure that the automount is working execute the following command: mount | grep auto The result should be like : auto.home on /exports/home type autofs (rw,relatime,fd=18,pgrp=19004,timeout=300,minproto=5,maxproto=5,indirect) If not edit /etc/nsswitch.conf find the automount line, sss may be missing it should be like : automount: files sss Fix it, restart sssd and autofs.","title":"Linux IPA Client"},{"location":"IT/FreeIPA/#freebsd","text":"","title":"FreeBSD"},{"location":"IT/FreeIPA/#freebsd-nfs-server","text":"","title":"FreeBSD NFS Server"},{"location":"IT/FreeIPA/#freebsd-ipa-client","text":"Source : - https://blog.hostileadmin.com/2016/03/24/integrating-freebsd-w-freeipasssd/ - https://forums.freebsd.org/threads/46526/ On the FreeBSD Client (not yet functional), compile sssd with smb support Edit sssd/Makefile and add the option --with-krb5-conf=/etc/krb5.conf (thx https://community.riocities.com/freebsd_nfv4_krb.html) freebsd_srv# mkdir -p /usr/compat/linux/proc freebsd_srv# echo \"linproc /usr/compat/linux/proc linprocfs rw 0 0\" >> /etc/fstab mkdir /var/log/krb5 edit /etc/pam.d/system TBF On the FreeIPA Server execute the following commands ipaserver# ipa-host-add FREEBSD_FQDN ipaserver# ipa-getkeytab -s ${HOSTNAME} -p host/FREEBSD_FQDN -k <location to export the keytab> Now, copy the newly created keytab file to /etc/krb5.keytab on the FreeBSD Client Add TLS_CACERT /etc/ipa/ca.crt in /usr/local/etc/openldap/ldap.conf","title":"FreeBSD IPA Client"},{"location":"IT/FreeIPA/#rules","text":"","title":"Rules"},{"location":"IT/FreeIPA/#allow-some-users-to-connect-throught-ssh","text":"Based on http://www.freeipa.org/page/Howto/HBAC_and_allow_all Create a new rule name allow_ssh ipaserver# ipa hbacrule-add allow_ssh Added HBAC rule \"allow_ssh\" Rule name: allow_ssh Enabled: TRUE Associate newly created HBAC rule ipaserver# ipa hbacrule-add-service allow_ssh --hbacsvcs=sshd Rule name: allow_ssh Enabled: TRUE Services: sshd Number of members added 1 Associate a User to this rule ipaserver# ipa hbacrule-add-user allow_ssh --user=username_allowed Rule name: allow_ssh Enabled: TRUE Users: username_allowed Number of members added 1 ipaserver# ipa hbacrule-add-host allow_ssh --hosts=ipaclient.myplace.local Rule name: allow_ssh Enabled: TRUE Users: username_allowed Hosts: ipaclient.myplace.local Number of members added 1","title":"Allow some users to connect throught ssh"},{"location":"IT/FreeIPA/#allow-some-users-to-excute-commands-with-sudo","text":"In the previous section about allowing ssh command, I've written the command output, but in the following one, I will not. Before allowing user to execute specific command through sudo, we need to allow the user to access sudo. ipaserver# ipa hbacrule-add allow_sudo ipaserver# ipa hbacrule-add-service allow_sudo --hbacsvcs=sudo ipaserver# ipa hbacrule-add-user allow_sudo --user=username_allowed ipaserver# ipa hbacrule-add-host allow_sudo --hosts=ipaclient.myplace.local Ok now let's allow the user execute a command like whoami. Beware that sssd is a caching system, so I can take time to refresh the data (up to 6h) - Incrementally, meaning only changes to rule since the last full update (ldap_sudo_smart_refresh_interval, the time in seconds); the default is 15 minutes, - Fully, which dumps the entire caches and pulls all the current rules on the LDAP server(ldap_sudo_full_refresh_interval, the time in seconds); the default is six hours. Source sssd-ldap-sudo ipaserver# ipa sudorule-add whoami ipaserver# ipa sudocmd-add /usr/bin/whoami ipaserver# ipa sudorule-add-allow-command whoami --sudocmds /usr/bin/whoami ipaserver# ipa sudorule-add-host whoami --hosts ipaclient.myplace.local ipaserver# ipa sudorule-add-user whoami --users username_allowed Now if we want to allow executing sudo whoami without autenticate the user we add this: ipaserver# ipa sudorule-add-option whoami --sudooption '!authenticate'","title":"Allow some users to excute commands with sudo"},{"location":"IT/OPNSense/freebox-bridge-ipv6/","text":"Description","title":"Description"},{"location":"IT/OPNSense/freebox-bridge-ipv6/#description","text":"","title":"Description"},{"location":"IT/cheatsheets/","text":"CheatSheets Ansible Python","title":"Cheatsheets"},{"location":"IT/cheatsheets/#cheatsheets","text":"Ansible Python","title":"CheatSheets"},{"location":"IT/cheatsheets/ansible/","text":"Some ansible Tips Combine vars Useful roles","title":"Some ansible Tips"},{"location":"IT/cheatsheets/ansible/#some-ansible-tips","text":"Combine vars Useful roles","title":"Some ansible Tips"},{"location":"IT/cheatsheets/ansible/combine/","text":"Merge vars Combine functionality to replace a specific value in a nested var Global/all.yml: sshd : Compression : true ListenAddress : - \"0.0.0.0\" - \"::\" PermitRootLogin : true hosts_vars/hostname.yml host_sshd : Compression : false PermitRootLogin : false roles/sshd.yml - name : Combine default and host vars set_fact : sshd : \"{{ sshd | combine(host_sshd) }}\" when : host_sshd is defined - name : \"Configure sshd\" include_role : name : willshersystems.sshd","title":"Combine"},{"location":"IT/cheatsheets/ansible/combine/#merge-vars","text":"Combine functionality to replace a specific value in a nested var Global/all.yml: sshd : Compression : true ListenAddress : - \"0.0.0.0\" - \"::\" PermitRootLogin : true hosts_vars/hostname.yml host_sshd : Compression : false PermitRootLogin : false roles/sshd.yml - name : Combine default and host vars set_fact : sshd : \"{{ sshd | combine(host_sshd) }}\" when : host_sshd is defined - name : \"Configure sshd\" include_role : name : willshersystems.sshd","title":"Merge vars"},{"location":"IT/cheatsheets/ansible/roles/","text":"List of useful roles: SSH : willshersystems.sshd","title":"Roles"},{"location":"IT/cheatsheets/ansible/roles/#list-of-useful-roles","text":"SSH : willshersystems.sshd","title":"List of useful roles:"},{"location":"IT/cheatsheets/python/python_tipstricks/","text":"Overall This is some Tips & Tricks about Python Strings cf twitter >>> import string >>> string . ascii_letters 'abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ >>> string . digits '0123456789' >>> string . hexdigits '0123456789abcdefABCDEF' >>> string . punctuation '!\"#$%& \\' ()*+,-./:;<=>?@[ \\\\ ]^_`{|}~'","title":"IT/Python Tips & Tricks"},{"location":"IT/cheatsheets/python/python_tipstricks/#overall","text":"This is some Tips & Tricks about Python","title":"Overall"},{"location":"IT/cheatsheets/python/python_tipstricks/#strings","text":"cf twitter >>> import string >>> string . ascii_letters 'abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ >>> string . digits '0123456789' >>> string . hexdigits '0123456789abcdefABCDEF' >>> string . punctuation '!\"#$%& \\' ()*+,-./:;<=>?@[ \\\\ ]^_`{|}~'","title":"Strings"},{"location":"domotics/","text":"Overall Following kiwi 's recommendation I will use domoticz and tasmota systems. I've tried to use some other systems like : Requirement A machine that will host your systems like a NAS (with docker) or a raspberry pi. Danger Using Debian 11 is not recommended as there is some issues with domoticz and python 3.9. Except if you use a docker based system in order to have the required version. Hardware I've ordered some sonoff switches that are compatible with tasmota via a quick flash of the esp. 2 buttons 3 buttons Warning some recent equipments are not tasmota compatible because of hardware update. So avoid systems like the following : Etersky 3 buttons switches LoraTap switches Systems MQTT system You can use a simple system like mosquitto that is available via Debian and Fedora repositories. Warning Don't forget to configure mosquitto to listen on lan interface with the following configuration option bind_interface eth0 Domoticz Addons [domoticz_mqtt_discovery](https://github.com/emontnemery/domoticz_mqtt_discovery]","title":"tasmota"},{"location":"domotics/#overall","text":"Following kiwi 's recommendation I will use domoticz and tasmota systems. I've tried to use some other systems like :","title":"Overall"},{"location":"domotics/#requirement","text":"A machine that will host your systems like a NAS (with docker) or a raspberry pi. Danger Using Debian 11 is not recommended as there is some issues with domoticz and python 3.9. Except if you use a docker based system in order to have the required version.","title":"Requirement"},{"location":"domotics/#hardware","text":"I've ordered some sonoff switches that are compatible with tasmota via a quick flash of the esp. 2 buttons 3 buttons Warning some recent equipments are not tasmota compatible because of hardware update. So avoid systems like the following : Etersky 3 buttons switches LoraTap switches","title":"Hardware"},{"location":"domotics/#systems","text":"","title":"Systems"},{"location":"domotics/#mqtt-system","text":"You can use a simple system like mosquitto that is available via Debian and Fedora repositories. Warning Don't forget to configure mosquitto to listen on lan interface with the following configuration option bind_interface eth0","title":"MQTT system"},{"location":"domotics/#domoticz","text":"","title":"Domoticz"},{"location":"domotics/#addons","text":"[domoticz_mqtt_discovery](https://github.com/emontnemery/domoticz_mqtt_discovery]","title":"Addons"},{"location":"domotics/tasmota/","text":"Tasmota Configuration Define Switches Model SonOff Switches (T0 EU 2 Gang Switch (T0EU2C)) Other Parameters / Model {\"NAME\":\"Sonoff T0 2CH\",\"GPIO\":[17,255,255,255,0,22,18,0,21,56,0,0,0],\"FLAG\":0,\"BASE\":29} {\"NAME\":\"Generic\",\"GPIO\":[32,1,1,1,0,225,33,0,224,320,0,0,0,0],\"FLAG\":0,\"BASE\":29} SonOff Switches (T0 EU 3 Gang Switch (T0EU3C)) Other Parameters / Model {\"NAME\":\"Sonoff T0 3CH\",\"GPIO\":[32,1,0,1,226,225,33,34,224,576,0,0,0,0],\"FLAG\":0,\"BASE\":30} Attach to MQTT for full discovery Backlog setoption19 1; MqttUser 0; MqttPassword 0; FullTopic homeassistant/%prefix%/%topic%/ Define a shutter switch Following tasmota official documentation First, close your blind and measure how much time it take to open it. Mine is 21s. Then define the switch as a shutter SetOption80 1 Define the default shutter mode Shutter mode 1 Group buttons 1 and 2 together and activate it Interlock 1,2 Interlock ON If possible to avoid any injury on unexpected movement all RELAYS should start in OFF mode when the device reboots: PowerOnState 0 As i've inverted the wire. ShutterButton 1 up ShutterButton 2 down Now we will configure the shutter with the measured time to close it. We will use this Google Spreadsheet Step 1 shutteropenduration 21 shuttercloseduration 21 ShutterSetHalfway 50 shuttermotordelay 1 shutteropenduration 21 shuttercloseduration 21 ShutterSetHalfway 50 shuttermotordelay 0 Ensure that your blind is closed and execute the following command to define the 0 position. Step 2 shuttersetclose Measure in cm the position of the blind on each action and fill the spreadsheet shutterposition 30 shutterposition 80 shutterposition 30 shuttercloseduration 21 shuttermotordelay 0.25 shuttercallibration 15.8 41.8 72.6 107.9 07:44:18.346 RSL: STATUS13 = {\"StatusSHT\":{\"SHT0\":{\"Relay1\":1,\"Relay2\":2,\"Open\":100,\"Close\":100,\"50perc\":50,\"Delay\":0,\"Opt\":\"0000\",\"Calib\":[300,500,700,900,1000],\"Mode\":\"0\"}}} Correction : shuttermotordelay 0.5 shutteropenduration 23 SetOption80 1 Shutter mode 1 Backlog Interlock 1 ,2 ; Interlock ON Backlog PowerOnState 0 ; ShutterButton 1 up ; ShutterButton 2 down ; shutteropenduration 21 ; shuttercloseduration 23 ; ShutterSetHalfway 50 ; shuttermotordelay 0 .5","title":"Tasmota"},{"location":"domotics/tasmota/#tasmota","text":"","title":"Tasmota"},{"location":"domotics/tasmota/#configuration","text":"","title":"Configuration"},{"location":"domotics/tasmota/#define-switches-model","text":"","title":"Define Switches Model"},{"location":"domotics/tasmota/#sonoff-switches-t0-eu-2-gang-switch-t0eu2c","text":"Other Parameters / Model {\"NAME\":\"Sonoff T0 2CH\",\"GPIO\":[17,255,255,255,0,22,18,0,21,56,0,0,0],\"FLAG\":0,\"BASE\":29} {\"NAME\":\"Generic\",\"GPIO\":[32,1,1,1,0,225,33,0,224,320,0,0,0,0],\"FLAG\":0,\"BASE\":29}","title":"SonOff Switches (T0 EU 2 Gang Switch (T0EU2C))"},{"location":"domotics/tasmota/#sonoff-switches-t0-eu-3-gang-switch-t0eu3c","text":"Other Parameters / Model {\"NAME\":\"Sonoff T0 3CH\",\"GPIO\":[32,1,0,1,226,225,33,34,224,576,0,0,0,0],\"FLAG\":0,\"BASE\":30}","title":"SonOff Switches (T0 EU 3 Gang Switch (T0EU3C))"},{"location":"domotics/tasmota/#attach-to-mqtt-for-full-discovery","text":"Backlog setoption19 1; MqttUser 0; MqttPassword 0; FullTopic homeassistant/%prefix%/%topic%/","title":"Attach to MQTT for full discovery"},{"location":"domotics/tasmota/#define-a-shutter-switch","text":"Following tasmota official documentation First, close your blind and measure how much time it take to open it. Mine is 21s. Then define the switch as a shutter SetOption80 1 Define the default shutter mode Shutter mode 1 Group buttons 1 and 2 together and activate it Interlock 1,2 Interlock ON If possible to avoid any injury on unexpected movement all RELAYS should start in OFF mode when the device reboots: PowerOnState 0 As i've inverted the wire. ShutterButton 1 up ShutterButton 2 down Now we will configure the shutter with the measured time to close it. We will use this Google Spreadsheet Step 1 shutteropenduration 21 shuttercloseduration 21 ShutterSetHalfway 50 shuttermotordelay 1 shutteropenduration 21 shuttercloseduration 21 ShutterSetHalfway 50 shuttermotordelay 0 Ensure that your blind is closed and execute the following command to define the 0 position. Step 2 shuttersetclose Measure in cm the position of the blind on each action and fill the spreadsheet shutterposition 30 shutterposition 80 shutterposition 30 shuttercloseduration 21 shuttermotordelay 0.25 shuttercallibration 15.8 41.8 72.6 107.9 07:44:18.346 RSL: STATUS13 = {\"StatusSHT\":{\"SHT0\":{\"Relay1\":1,\"Relay2\":2,\"Open\":100,\"Close\":100,\"50perc\":50,\"Delay\":0,\"Opt\":\"0000\",\"Calib\":[300,500,700,900,1000],\"Mode\":\"0\"}}} Correction : shuttermotordelay 0.5 shutteropenduration 23 SetOption80 1 Shutter mode 1 Backlog Interlock 1 ,2 ; Interlock ON Backlog PowerOnState 0 ; ShutterButton 1 up ; ShutterButton 2 down ; shutteropenduration 21 ; shuttercloseduration 23 ; ShutterSetHalfway 50 ; shuttermotordelay 0 .5","title":"Define a shutter switch"}]}